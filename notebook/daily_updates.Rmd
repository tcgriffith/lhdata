---
title: "Untitled"
author: "TC"
date: "October 24, 2017"
output: html_document
---

```{r setup, include=FALSE,message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(lubridate)
pkg_path="~/GIT/lhdata"
post_path="~/GIT/owaraisite/content/post/"

if (Sys.info()["sysname"]=="Windows"){
  pkg_path="c:/Users/TC/GIT/lhdata"
  post_path="c:/Users/TC/GIT/owaraisite/content/post/"
}

source(encoding="UTF-8",file=paste0(pkg_path,"/R/api_getuploads.R"))
source(encoding="UTF-8",file=paste0(pkg_path,"/R/api_getuploads_fp.R"))
source(encoding="UTF-8",file=paste0(pkg_path,"/R/getbangumi.R"))
source(encoding="UTF-8",file=paste0(pkg_path,"/R/getyearsdf.R"))
source(encoding="UTF-8",file=paste0(pkg_path,"/R/api_aid2cid.R"))
source(encoding="UTF-8",file=paste0(pkg_path,"/R/api_getbilitags.R"))
source(encoding="UTF-8",file=paste0(pkg_path,"/R/api_upload_imgur.R"))
source(encoding="UTF-8",file=paste0(pkg_path,"/R/generate_posts2.R"))
source(encoding="UTF-8",file=paste0(pkg_path,"/R/annotate_vlist_tmp.R"))
source(encoding="UTF-8",file=paste0(pkg_path,"/R/fromJSON_fix.R"))

# source(encoding="UTF-8",file=paste0(pkg_path,"/R/annotate_vlist.R"))
load(paste0(pkg_path,"/data/mid.rda"))

if (file.exists("/data/manual_filter.rda")){
  load(paste0(pkg_path,"/data/manual_filter.rda"))
}else {
  manual_filter=data.frame(aid=NA)
}
```

```{r eval=FALSE}



mid.df <- data.frame(mids = c(5382023,
                              207626,
                              2301165,
                              26666749,
                              97990,
                              8665350,
                              381936,
                              764931),
                     author = c("九條",
                                "莱姆籽",
                                "天翼羽魂",
                                "来一发就走字幕组",
                                "小山君",
                                "叔叔",
                                "汉中则为橙",
                                "sclarkca_"),
                     zmz = c("伦敦之心字幕组",
                             "伦敦之心字幕组",
                             "伦敦之心字幕组",
                             "来一发就走字幕组",
                             "大喜利王字幕组",
                             "4431字幕组",
                             "风物诗字幕组",
                             "hitori字幕组"
                             ),
                     kw = c("",
                            "伦敦之心字幕组",
                            "人力",
                            "",
                            "",
                            "字幕",
                            "风物诗字幕组",
                            "字幕"),
                     stringsAsFactors = FALSE)
save(mid.df,file=paste0(pkg_path,"/data/mid.rda"))

```




## downloadthings

```{r}
message("###########################################################")
message(Sys.time())
message("...start scraping\n")
#source(encoding="UTF-8",file=paste0(pkg_path,"/R/api_getuploads.R")


vlist.all <- data.frame()

for ( i in c(1,4:8)){
  vlist <- api_getuploads_fp(mid.df$mids[i],kw=mid.df$kw[i])
  vlist$zmz=mid.df$zmz[i]
  vlist.all <- rbind(vlist.all,vlist)
}



## get new vlist
p= list.files(post_path)
oldaid <- ((gsub('^.*-(.*).md$','\\1',p)))


vlist.new <- vlist.all %>% 
  filter(!aid %in% oldaid, !aid %in% manual_filter$aid)



message("###########################################################")

message(paste0("...scraping finished, ",nrow(vlist.new)," new posts"))
if (nrow(vlist.new)==0) {
  message("...no new post detected, quitting script")
  q('no')
} else{
  writeLines(vlist.new$title)
}

```


```{r eval=FALSE}
filter_update <- unique(rbind(manual_filter,data.frame(aid=oldaid)))

manual_filter <- data.frame(aid=oldaid)
save(manual_filter,file=paste0(pkg_path,"/data/manual_filter.rda"))
```

## manually fetching


```{r test, eval=FALSE}
vlist.new <-api_getuploads(5858153,kw = "翻唱")

vlist.new$zmz="伦敦之心字幕组"

#vlist.new.anno$zmz="伦敦之心字幕组"
```


```{r test2, eval=FALSE}
##三葉__ 东京03

vlist.new <-api_getuploads(119571380,kw = "短剧+字幕")

vlist.new$zmz="个人字幕组"

#vlist.new.anno$zmz="伦敦之心字幕组"
```

```{r test3, eval=FALSE}
# akihoni 东京03 412335

vlist.new <-api_getuploads(412335,kw = "东京03+字幕")

vlist.new$zmz="个人字幕组"


```

```{r test4, eval=FALSE}
# 长野县名产翅膀 ametalk 1464994

vlist.new <-api_getuploads(1464994,kw = "字幕")

vlist.new$zmz="个人字幕组"

```



```{r test5, eval= FALSE}
# 汉中则为橙 381936 ametalk 


vlist.newm <-api_getuploads(381936,kw = "风物诗字幕组")

# vlist.new <- vlist.new %>%
#   filter(grepl("ametalk|rahmens|speedwagon",title,ignore.case = TRUE))

vlist.newm$zmz="风物诗字幕组"

p= list.files(post_path)
oldaid <- ((gsub('^.*-(.*).md$','\\1',p)))


vlist.new <- vlist.newm %>% 
  filter(!aid %in% oldaid, !aid %in% manual_filter$aid)




```

```{r test6, eval= FALSE}
# sclarkca_ 764931 字幕 


vlist.newm <-api_getuploads(764931,kw = "字幕")

# vlist.new <- vlist.new %>%
#   filter(grepl("ametalk|rahmens|speedwagon",title,ignore.case = TRUE))

vlist.newm$zmz="风物诗字幕组"

p= list.files(post_path)
oldaid <- ((gsub('^.*-(.*).md$','\\1',p)))


vlist.new <- vlist.newm %>% 
  filter(!aid %in% oldaid, !aid %in% manual_filter$aid)




```


## add info

```{r}
## vlist add more columns using api
## require vlist.new
message("###########################################################")
message("...starting downloading pics\n")
#source("../R/annotate_vlist.R")
vlist.new.anno <-annotate_vlist(vlist.new)

```

## output

```{r}
message("###########################################################")
message("...starting generating pics")
message("###########################################################")

generate_post2(vlist.new.anno,post_path)
```




## test

```{r eval=FALSE}
api_upload_imgur()
```

